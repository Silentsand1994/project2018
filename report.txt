Input:
讀入音訊(使用librosa): 	
	抽取features，包含過零率、RMSE、MFCC12共14個特徵。
	音訊取樣頻率:22050
	音框長度:2048
	重疊音框長度:512

將取出的features用Kmeans做分群(使用sklearn.cluster)做出feature map

將音訊對應的map內容放入word2vec(使用gensim)內產生相對應向量

輸出對應向量作為訓練的資料

將訓練資料放入CNN(目前是使用keras) 
keras的CNN需要固定輸入資料，將輸入資料固定為最長音框數。->會使資料產生偏差 ->預計修改使用torch

訓練結果：
將八種情緒資料(1320筆)平分為5份分別做train&test(epochs=30):

Round0
test loss: 0.875790379997
test accuracy: 0.642857142409
Round1
test loss: 0.737126955412
test accuracy: 0.684210525868
Round2
test loss: 0.810179703865
test accuracy: 0.660377359165
Round3
test loss: 0.868771216715
test accuracy: 0.627376426309
Round4
test loss: 0.784345247195
test accuracy: 0.642307692308